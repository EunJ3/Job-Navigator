# üìÅ ÌååÏùº Í≤ΩÎ°ú: ai/crawler/services/jumpit_crawler.py

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.chrome.webdriver import Options
from time import sleep
from .job_classifier import classify_job  # üîç ÏßÅÎ¨¥ Î∂ÑÎ•ò Ìï®Ïàò import


def get_jumpit_jobs() -> list[dict]:
    """
    Jumpit ÏõπÏÇ¨Ïù¥Ìä∏ÏóêÏÑú Ï±ÑÏö© Í≥µÍ≥†Î•º ÌÅ¨Î°§ÎßÅÌïòÏó¨ dict Î¶¨Ïä§Ìä∏Î°ú Î∞òÌôòÌï©ÎãàÎã§.
    - title, company, location, experience, tech_stack(list), deadline, url Îì± Ìè¨Ìï®
    - classify_job() Ìï®ÏàòÎ•º ÌÜµÌï¥ job_type ÏûêÎèô Î∂ÑÎ•ò
    - Í∏∞Î≥∏Ï†ÅÏúºÎ°ú Î™®Îì† Í≥µÍ≥†Îäî is_active=TrueÎ°ú Ï†ÄÏû•
    """

    options = Options()
    # options.add_argument("--headless")  # GUI ÏóÜÏï†Î†§Î©¥ Ï£ºÏÑù Ìï¥Ï†ú
    driver = webdriver.Chrome(options=options)

    # ‚úÖ Jumpit Ï±ÑÏö© ÌéòÏù¥ÏßÄ Ïó¥Í∏∞
    driver.get("https://jumpit.saramin.co.kr/positions?sort=rsp_rate")
    sleep(3)

    # ‚úÖ ÌåùÏóÖ Îã´Í∏∞ (Ï°¥Ïû¨ÌïòÎ©¥)
    try:
        close_btn = driver.find_element(By.CSS_SELECTOR, "body > main > div > div.sc-a0301295-0.btHfXC > div > div > button")
        close_btn.click()
        sleep(1)
    except Exception:
        pass

    # ‚úÖ ÌéòÏù¥ÏßÄ ÎÅùÍπåÏßÄ Ïä§ÌÅ¨Î°§ Îã§Ïö¥
    last_height = driver.execute_script("return document.body.scrollHeight")
    while True:
        driver.find_element(By.TAG_NAME, "body").send_keys(Keys.END)
        sleep(1.5)
        new_height = driver.execute_script("return document.body.scrollHeight")
        if new_height == last_height:
            break
        last_height = new_height

    # ‚úÖ Í≥µÍ≥† ÏàòÏßë
    jobs = []
    cards = driver.find_elements(By.CSS_SELECTOR, "a[href^='/position/']")
    print(f"üì¶ ÏàòÏßëÎêú Í≥µÍ≥† Ïàò: {len(cards)}Í∞ú")

    for card in cards:
        try:
            full_url = "https://jumpit.saramin.co.kr" + card.get_attribute("href")

            title = card.find_element(By.CSS_SELECTOR, "h2").text.strip()

            # ‚úÖ Ï†ïÌôïÌïú ÌöåÏÇ¨Î™Ö Ï∂îÏ∂ú (wrapper ÎÇ¥ Ï≤´ Î≤àÏß∏ div > span)
            wrapper = card.find_element(By.CSS_SELECTOR, "div.sc-15ba67b8-0.kkQQfR")
            company = wrapper.find_element(By.CSS_SELECTOR, "div:nth-of-type(1) > span").text.strip()

            tech_list = card.find_elements(By.CSS_SELECTOR, "ul.sc-15ba67b8-1.iFMgIl > li")
            tech_stack = [li.text.strip() for li in tech_list if li.text.strip()]

            info_list = card.find_elements(By.CSS_SELECTOR, "ul.sc-15ba67b8-1.cdeuol > li")
            location = info_list[0].text.strip() if len(info_list) > 0 else "ÎØ∏ÏÉÅ"
            experience = info_list[1].text.strip() if len(info_list) > 1 else "Í≤ΩÎ†• Î¨¥Í¥Ä"

            try:
                deadline = card.find_element(
                    By.CSS_SELECTOR,
                    "div.img_box > div.sc-d609d44f-3.hwTKyC > span"
                ).text.strip()
            except Exception:
                deadline = "ÎßàÍ∞êÏùº ÎØ∏Ï†ï"

            job_type = classify_job(title, ", ".join(tech_stack))

            jobs.append({
                "title": title,
                "company": company,
                "location": location,
                "experience": experience,
                "tech_stack": tech_stack,
                "due_date_text": deadline,
                "url": full_url,
                "job_type": job_type,
                "is_active": True,
            })

        except Exception as e:
            print(f"‚ùå ÌÅ¨Î°§ÎßÅ Ïò§Î•ò: {e}")
            continue

    driver.quit()
    return jobs
