import os
import json
import time
import re
import nltk
from tqdm import tqdm
import mlflow
from nltk.tokenize import sent_tokenize
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from dotenv import load_dotenv
import sys
from pathlib import Path

# ‚úÖ NLTK Îã§Ïö¥Î°úÎìú
try:
    nltk.download('punkt', quiet=True)
    nltk.download('punkt_tab', quiet=True)
except:
    pass

load_dotenv()

sys.path.append(str(Path(__file__).resolve().parent.parent.parent))
from ai.tech_dict import TECH_STACK

model = SentenceTransformer("all-MiniLM-L6-v2")

def load_dataset(path):
    with open(path, "r", encoding="utf-8") as f:
        return [json.loads(line) for line in f]

# ‚úÖ ÏàòÏ†ïÎêú ÏÇ¨Ï†Ñ Í∏∞Î∞ò Îß§Ïπ≠ (ÌïúÍµ≠Ïñ¥ Ï°∞ÏÇ¨ Í≥†Î†§)
def dictionary_based_matching(text, tech_stack):
    found = set()
    for tech in tech_stack:
        # ‚úÖ ÌïúÍµ≠Ïñ¥ Ï°∞ÏÇ¨Î•º Í≥†Î†§Ìïú Ìå®ÌÑ¥Îì§
        patterns = [
            rf'\b{re.escape(tech)}\b',  # Í∏∞Î≥∏ Îã®Ïñ¥ Í≤ΩÍ≥Ñ
            rf'{re.escape(tech)}(?=[ÏùÑÎ•ºÏù¥Í∞ÄÎäîÏùÄÏóêÏÑúÏôÄÍ≥º])',  # ÌïúÍµ≠Ïñ¥ Ï°∞ÏÇ¨ Ïïû
            rf'{re.escape(tech)}(?=\s)',  # Í≥µÎ∞± Ïïû
            rf'{re.escape(tech)}(?=[.,!?])',  # Íµ¨ÎëêÏ†ê Ïïû
        ]
        
        for pattern in patterns:
            if re.search(pattern, text, re.IGNORECASE):
                found.add(tech)
                break  # ÌïòÎÇòÎùºÎèÑ Îß§Ïπ≠ÎêòÎ©¥ Ï∂îÍ∞ÄÌïòÍ≥† Îã§Ïùå Í∏∞Ïà†Î°ú
    
    return found

# ‚úÖ ÏàòÏ†ïÎêú ÏûÑÎ≤†Îî© Í∏∞Î∞ò Îß§Ïπ≠ (threshold Î≥ÄÍ≤Ω Í∞ÄÎä•)
def embedding_based_matching(text, tech_stack, threshold=0.6): 
    try:
        sentences = sent_tokenize(text)
        if not sentences:
            sentences = [text]
        
        s_emb = model.encode(sentences)
        k_emb = model.encode(tech_stack)
        found = set()
        
        for vec in s_emb:
            sims = cosine_similarity([vec], k_emb)[0]
            for tech, score in zip(tech_stack, sims):
                if score >= threshold:
                    found.add(tech)
        return found
    except Exception as e:
        print(f"‚ùå ÏûÑÎ≤†Îî© Îß§Ïπ≠ Ïò§Î•ò: {e}")
        return set()

# ‚úÖ ÌïòÏù¥Î∏åÎ¶¨Îìú Ï∂îÏ∂ú
def extract_keywords_from_text(text, tech_stack):
    dict_result = dictionary_based_matching(text, tech_stack)
    embed_result = embedding_based_matching(text, tech_stack)
    combined = dict_result | embed_result
    return list(combined)

# ‚úÖ ÌèâÍ∞Ä Ìï®Ïàò
def evaluate_keywords(predicted, actual, top_k=5):
    pred_set = set(predicted)
    true_set = set(actual)
    tp = len(pred_set & true_set)
    fp = len(pred_set - true_set)
    fn = len(true_set - pred_set)
    precision = tp / (tp + fp + 1e-10)
    recall = tp / (tp + fn + 1e-10)
    f1 = 2 * precision * recall / (precision + recall + 1e-10)
    top_k_accuracy = int(len(set(predicted[:top_k]) & true_set) > 0)
    return precision, recall, f1, top_k_accuracy

# ‚úÖ ÌÇ§ÏõåÎìú Ï∂îÏ∂ú Ìï®Ïàò
def extract_keywords(model_name, text, top_n=5):
    if model_name == "DictionaryOnly":
        return list(dictionary_based_matching(text, TECH_STACK))
    elif model_name == "EmbeddingOnly":
        return list(embedding_based_matching(text, TECH_STACK, threshold=0.6))
    elif model_name == "HybridDict+Embedding":
        return extract_keywords_from_text(text, TECH_STACK)
    else:
        raise ValueError(f"Unknown model: {model_name}")

# ‚úÖ ÎîîÎ≤ÑÍπÖ Ìï®Ïàò Í∞ïÌôî
def debug_first_sample(data):
    print("\nüîç Ï≤´ Î≤àÏß∏ ÏÉòÌîå ÏÉÅÏÑ∏ ÎîîÎ≤ÑÍπÖ:")
    first_item = data[0]
    text = first_item['sentence']
    true_keywords = first_item['keywords']
    
    print(f"üìù Ï†ÑÏ≤¥ Î¨∏Ïû•: {text}")
    print(f"üéØ Ï†ïÎãµ: {true_keywords}")
    
    # Í∞úÎ≥Ñ ÌÇ§ÏõåÎìúÎ≥Ñ Îß§Ïπ≠ ÌÖåÏä§Ìä∏
    print(f"\nüîç Í∞úÎ≥Ñ ÌÇ§ÏõåÎìú Îß§Ïπ≠ ÌÖåÏä§Ìä∏:")
    for keyword in true_keywords:
        # Í∏∞Î≥∏ Ìå®ÌÑ¥
        basic_match = bool(re.search(rf'\b{re.escape(keyword)}\b', text, re.IGNORECASE))
        # ÌïúÍµ≠Ïñ¥ Ï°∞ÏÇ¨ Ìå®ÌÑ¥
        korean_match = bool(re.search(rf'{re.escape(keyword)}(?=[ÏùÑÎ•ºÏù¥Í∞ÄÎäîÏùÄÏóêÏÑúÏôÄÍ≥º])', text, re.IGNORECASE))
        # Í≥µÎ∞± Ìå®ÌÑ¥
        space_match = bool(re.search(rf'{re.escape(keyword)}(?=\s)', text, re.IGNORECASE))
        
        print(f"   {keyword}: Í∏∞Î≥∏={basic_match}, Ï°∞ÏÇ¨={korean_match}, Í≥µÎ∞±={space_match}")
        
        # ÌÖçÏä§Ìä∏ÏóêÏÑú Ìï¥Îãπ ÌÇ§ÏõåÎìú Ï£ºÎ≥Ä ÌôïÏù∏
        if keyword in text:
            idx = text.find(keyword)
            context = text[max(0, idx-10):idx+len(keyword)+10]
            print(f"     ‚Üí Î¨∏Îß•: ...{context}...")

    # Ïã§Ï†ú Ï∂îÏ∂ú ÌÖåÏä§Ìä∏
    dict_result = list(dictionary_based_matching(text, TECH_STACK))
    embed_result = list(embedding_based_matching(text, TECH_STACK, threshold=0.6))
    hybrid_result = extract_keywords_from_text(text, TECH_STACK)
    
    print(f"\nüìä Ï∂îÏ∂ú Í≤∞Í≥º:")
    print(f"   üìö ÏÇ¨Ï†Ñ Îß§Ïπ≠: {dict_result}")
    print(f"   üß† ÏûÑÎ≤†Îî© Îß§Ïπ≠ (0.6): {embed_result}")
    print(f"   üîÑ ÌïòÏù¥Î∏åÎ¶¨Îìú: {hybrid_result}")

# ‚úÖ Ïã§Ìóò Ïã§Ìñâ Ìï®Ïàò (Ïã§ÌóòÎ™Ö Î≥ÄÍ≤Ω)
def run_experiment(dataset_path, models):
    print(f"\nüìä Îç∞Ïù¥ÌÑ∞ÏÖã Î°úÎî©: {dataset_path}")
    data = load_dataset(dataset_path)
    print(f"‚úÖ Îç∞Ïù¥ÌÑ∞ ÌÅ¨Í∏∞: {len(data)}")
    print(f"üìö TECH_STACK ÌÅ¨Í∏∞: {len(TECH_STACK)}")
    
    # Ï≤´ Î≤àÏß∏ ÏÉòÌîå ÎîîÎ≤ÑÍπÖ
    debug_first_sample(data)
    
    # ‚úÖ MLflow Ïã§ÌóòÎ™Ö Î≥ÄÍ≤Ω (ÏÇ≠Ï†úÎêú Ïã§Ìóò Î¨∏Ï†ú Ìï¥Í≤∞)
    experiment_name = f"Korean-Dictionary-Keyword-Extraction-{int(time.time())}"
    mlflow.set_experiment(experiment_name)
    print(f"üîß MLflow Ïã§Ìóò: {experiment_name}")

    for model_name in models:
        print(f"\nüöÄ Testing Model: {model_name}")
        
        precisions, recalls, f1s, top_ns, top_k_hits = [], [], [], [], []
        start_time = time.time()
        results = []

        with mlflow.start_run(run_name=f"{model_name}_korean_optimized"):
            mlflow.log_param("dataset_version", "v2")
            mlflow.log_param("algorithm", model_name)
            mlflow.log_param("tech_stack_size", len(TECH_STACK))
            mlflow.log_param("sentence_tokenizer", "nltk_sent_tokenize")
            mlflow.log_param("korean_optimized", True)  # ‚úÖ ÌïúÍµ≠Ïñ¥ ÏµúÏ†ÅÌôî ÌëúÏãú
            if "Embedding" in model_name:
                mlflow.log_param("embedding_model", "all-MiniLM-L6-v2")
                mlflow.log_param("threshold", 0.6)  # ‚úÖ threshold ÎÇÆÏ∂§

            for idx, item in enumerate(tqdm(data, desc=f"Processing {model_name}")):
                sentence = item["sentence"]
                true_keywords = item["keywords"]

                top_n = len(true_keywords) if len(true_keywords) > 0 else 1
                top_ns.append(top_n)

                try:
                    predicted_keywords = extract_keywords(model_name, sentence, top_n=top_n)
                    p, r, f1, top_k_hit = evaluate_keywords(predicted_keywords, true_keywords)
                except Exception as e:
                    print(f"‚ùå Error processing item {idx}: {e}")
                    predicted_keywords = []
                    p, r, f1, top_k_hit = 0, 0, 0, 0

                precisions.append(p)
                recalls.append(r)
                f1s.append(f1)
                top_k_hits.append(top_k_hit)

                result = {
                    "sentence": sentence,
                    "true_keywords": true_keywords,
                    "predicted_keywords": predicted_keywords,
                    "precision": round(p, 4),
                    "recall": round(r, 4),
                    "f1": round(f1, 4),
                    "top_5_hit": top_k_hit,
                }
                results.append(result)

                # Ï≤òÏùå 3Í∞ú ÏÉòÌîå Ï∂úÎ†•
                if idx < 3:
                    print(f"\n[Sample {idx+1}]")
                    print(f"Sentence: {sentence}")
                    print(f"True: {true_keywords}")
                    print(f"Pred: {predicted_keywords}")
                    print(f"P={p:.3f}, R={r:.3f}, F1={f1:.3f}, Top-5 Hit={top_k_hit}")

            # ÌèâÍ∑† Í≥ÑÏÇ∞
            avg_p = sum(precisions) / len(precisions)
            avg_r = sum(recalls) / len(recalls)
            avg_f1 = sum(f1s) / len(f1s)
            avg_top_n = sum(top_ns) / len(top_ns)
            avg_top_k_acc = sum(top_k_hits) / len(top_k_hits)
            duration = time.time() - start_time

            # MLflow Î°úÍπÖ
            mlflow.log_metric("avg_precision", avg_p)
            mlflow.log_metric("avg_recall", avg_r)
            mlflow.log_metric("avg_f1", avg_f1)
            mlflow.log_metric("avg_top_n", avg_top_n)
            mlflow.log_metric("duration_sec", duration)
            mlflow.log_metric("top5_accuracy", avg_top_k_acc)

            print(f"\nüìä [{model_name}] Results:")
            print(f"   Precision: {avg_p:.4f}")
            print(f"   Recall: {avg_r:.4f}")
            print(f"   F1 Score: {avg_f1:.4f}")
            print(f"   Top-5 Accuracy: {avg_top_k_acc:.4f}")
            print(f"   Duration: {duration:.2f}s")

    print(f"\n‚úÖ All experiments completed!")
    print(f"üìä MLflow UI: http://localhost:5000")
    
if __name__ == "__main__":
    # ‚úÖ Î™®Îì† Î™®Îç∏ ÌÖåÏä§Ìä∏
    models_to_run = [
        "DictionaryOnly",           # ÏÇ¨Ï†Ñ Îß§Ïπ≠Îßå
        "EmbeddingOnly",           # ÏûÑÎ≤†Îî© Îß§Ïπ≠Îßå (threshold=0.6)
        "HybridDict+Embedding"     # ÏÇ¨Ï†Ñ + ÏûÑÎ≤†Îî© ÌïòÏù¥Î∏åÎ¶¨Îìú
    ]
    
    print("üöÄ Starting Korean-Optimized Dictionary Keyword Extraction...")
    print(f"üéØ Testing models: {models_to_run}")
    run_experiment("data/keywords_dataset.v2.jsonl", models=models_to_run)
